{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5cApalVyWZc"
      },
      "source": [
        "\n",
        "Perform Logistic Regression on the datasets of your choice. Compute accuracy, precision, recall, and F1-score for the predictions.\n",
        "Extend the code to handle multi-class classification using the softmax function. Search and try to implement any one research article (Conference or Journal) on Logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ebMOWxcKxHa8"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2H_qhO2xxnuv",
        "outputId": "c4c3ba99-0424-4193-e0ab-0e1b4d259078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9474\n",
            "Precision: 1.0000\n",
            "Recall:    0.9155\n",
            "F1 Score:  0.9559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-d6b903af6bc9>:14: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-z))\n"
          ]
        }
      ],
      "source": [
        "# database\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# bias\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# sigmoid\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# cf\n",
        "def compute_cost(X, y, weights):\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(X, weights))\n",
        "    return (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "# gradient descent\n",
        "def gradient_descent(X, y, weights, lr, epochs):\n",
        "    m = len(y)\n",
        "    for _ in range(epochs):\n",
        "        h = sigmoid(np.dot(X, weights))\n",
        "        gradient = np.dot(X.T, (h - y)) / m\n",
        "        weights -= lr * gradient\n",
        "    return weights\n",
        "\n",
        "\n",
        "weights = np.zeros(X_train.shape[1])\n",
        "\n",
        "weights = gradient_descent(X_train, y_train, weights, lr=0.01, epochs=1000)\n",
        "\n",
        "\n",
        "def predict(X, weights):\n",
        "    return (sigmoid(np.dot(X, weights)) >= 0.5).astype(int)\n",
        "\n",
        "\n",
        "y_pred = predict(X_test, weights)\n",
        "\n",
        "# calculations\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
        "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
        "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    return 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
        "\n",
        "# calculation\n",
        "acc = accuracy(y_test, y_pred)\n",
        "prec = precision(y_test, y_pred)\n",
        "rec = recall(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# res\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP8ZQUzgx-dY"
      },
      "source": [
        "MULTI CLASS REGRESSION on another dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g6T7haNhyBxW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UmZ4ZlZoyJay",
        "outputId": "fb88ccad-ddf6-4c75-c580-803477a7eae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report (Multi-class):\n",
            " Class 0: Precision=1.0000, Recall=1.0000, F1 Score=1.0000\n",
            "Class 1: Precision=1.0000, Recall=1.0000, F1 Score=1.0000\n",
            "Class 2: Precision=1.0000, Recall=1.0000, F1 Score=1.0000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# bias\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# softmax\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "# cf\n",
        "def compute_cost(X, y, weights):\n",
        "    m = len(y)\n",
        "    logits = np.dot(X, weights)\n",
        "    probs = softmax(logits)\n",
        "    y_one_hot = np.eye(weights.shape[1])[y]\n",
        "    return -np.sum(y_one_hot * np.log(probs)) / m\n",
        "\n",
        "# gradient descent\n",
        "def gradient_descent(X, y, weights, lr, epochs):\n",
        "    m = len(y)\n",
        "    y_one_hot = np.eye(weights.shape[1])[y]\n",
        "    for _ in range(epochs):\n",
        "        logits = np.dot(X, weights)\n",
        "        probs = softmax(logits)\n",
        "        gradient = np.dot(X.T, (probs - y_one_hot)) / m\n",
        "        weights -= lr * gradient\n",
        "    return weights\n",
        "\n",
        "\n",
        "weights = np.zeros((X_train.shape[1], len(np.unique(y))))\n",
        "\n",
        "\n",
        "weights = gradient_descent(X_train, y_train, weights, lr=0.01, epochs=1000)\n",
        "\n",
        "\n",
        "def predict(X, weights):\n",
        "    return np.argmax(softmax(np.dot(X, weights)), axis=1)\n",
        "\n",
        "\n",
        "y_pred = predict(X_test, weights)\n",
        "\n",
        "# calculation\n",
        "def classification_report_manual(y_true, y_pred):\n",
        "    classes = np.unique(y_true)\n",
        "    report = \"\"\n",
        "    for c in classes:\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fp = np.sum((y_pred == c) & (y_true != c))\n",
        "        fn = np.sum((y_pred != c) & (y_true == c))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        report += f\"Class {c}: Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\\n\"\n",
        "    return report\n",
        "\n",
        "# res\n",
        "print(\"Classification Report (Multi-class):\\n\", classification_report_manual(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
